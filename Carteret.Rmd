---
title: "Carteret"
author: "Tianyu Zhang"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: yes
    toc: yes
    theme: flatly
    toc_float: yes
    code_folding: hide
    number_sections: no
---

<style>
.kable thead tr th, .table thead tr th {
  text-align: left !important;}
table.kable, table.table {
  width: 100% !important;}
  body {
  line-height: 1.6;
  font-size: 16px
}
</style>

# Load Data

```{r}
if(!require(pacman)){install.packages("pacman"); library(pacman)}
p_load(tidyverse, sf, units)

setwd("C:/Users/ztyuu/Documents/Spring2024/Research/Ghost Forest")

Carteret.sf <- st_read("Carteret_CarteretCountyInfoTechDept/Tax_Parcel_Data.shp")
```

# Processing Parcel Records

## Cleaning Outliers

### Identifying Outliers

A significant amount of parcels where PIN15=00 000 and PIN15 is.na (Rows, Bridges etc.) are discerned from the duplicate list and extracted into distinct feature layers in R.

```{r PIN15 is "00      000" or NA}
C.00 <- Carteret.sf %>%
  as_tibble()%>%
  filter(PIN15 == "00      000")

C.NA <- Carteret.sf %>% 
  as_tibble() %>% 
  filter(is.na(PIN15))
```

Also, many duplicates in the dataset are WATER records (not-owned property). I created a separate dataset to identify these water bodies.

```{r Water}
Water <- Carteret.sf %>%
  as_tibble()%>%
  filter(PIN == "WATER")
```

To view these cleaned parcels, please create an additional line to write the respective shapefiles.

### Removing Outliers from the Major Dataset

```{r}
Carteret.sf <- Carteret.sf %>%
  anti_join(C.00) %>% 
  anti_join(C.NA) %>% 
  anti_join(Water)
```

# Check for Duplicates based on PIN15

```{r check PIN15 duplicates}
#C.geo.asdf <- Carteret.sf %>%
  #as_tibble()%>%
  #group_by(geometry) %>% 
  #tally() %>% 
  #filter(n>1)

C.pin.asdf <- Carteret.sf %>%
  as_tibble()%>%
  group_by(PIN15) %>% 
  tally() %>% 
  filter(n>1) %>% 
  inner_join(Carteret.sf, by = "PIN15")

#C.asdf <- C.geo.asdf %>% 
 #full_join(C.pin.asdf) #used this step to confirm all geographical duplicates are encompassed by pin duplicates
```

## Removing False Boundary Components

It is found that the Carteret dataset contains false boundary shape components (where the "polygon" is the boundary only). We assumed that the polygon with largest shape area is the actual parcel, and filtered duplicates with largest shape area.

```{r PIN15 dup filter by area}
C.dups <- C.pin.asdf

C.dups <- C.dups %>% 
  group_by(PIN15) %>% 
  filter(SHAPESTAre == max(SHAPESTAre))
```

The first step yields 31 parcel records with duplicated PIN15 data for 17 unique parcels. No critical polygon info is lost, affirming the validity of the treatment.

## Extracting Current Records

PIN duplicates is a result of multiple record entries under the same geographic parcel. To target the up-to-date owner information and land asset value, a two-round elimination is completed.

- Filtered parcel to their most current *ownership*: used DBOOK as a proxy for time since some DDATE are nas.

- Filtered parcel by their *best available value estimate*.   

```{r}
#filtering parcel to their most current ownership; used DBOOK as a proxy for time since some DDATE are nas.
C.dups.owner <- C.dups %>%
  group_by(PIN15) %>%
  filter(n() == 1 | (n() > 1 & DBOOK == max(as.numeric(DBOOK)))) %>%
  select(-c(LAND_VALUE, STRUC_VAL, OTHER_VAL))

#filtering parcel by their best available value estimate         
C.dups.value <- C.dups %>%
  group_by(PIN15) %>%
  filter(n() == 1 | (n() > 1 & LAND_VALUE == max(as.numeric(LAND_VALUE)))) %>%
  select(PIN15, LAND_VALUE, STRUC_VAL, OTHER_VAL)

#combining most current ownership and best available value info for each parcel that was duplicated originally
C.dups <- C.dups.owner %>%
  left_join(C.dups.value, by = c("PIN15" = "PIN15"))%>%
  select(-n)
```

# Identifying Unique PIN15 Records

```{r}
C.unique <- Carteret.sf %>%
  as_tibble()%>%
  group_by(PIN15) %>%
  tally() %>%
  filter(n==1)%>%
  select(PIN15) %>% 
  inner_join(Carteret.sf, by = "PIN15")
```

Binding the 17 cleaned duplicate parcels to the dataset.Since each parcel only has ONE record now, they are assigned Duped_Value = 0.

```{r}
CarteretMaster.0<- rbind(C.unique, C.dups) %>% 
  mutate(Duped_Value = "0")
```

# Additional Steps Based on ArcGIS - Fake Duplicates

Fake duplicate parcels (parcels with distinct *geographic* infomation) associated with PIN15 = "734802796634000" & "536602759906000" were falsely removed from the previous step. The value shown for each "fake duplicate" parcel is the aggregated value (double checked Carteret Deed website), and the ownership info is identical.

Took one more step to remove parcels "734802796634000" and "536602759906000" from the unique parcel dataset.

```{r}
CarteretMaster.0 <- CarteretMaster.0 %>% 
  filter(PIN15 != "734802796634000") %>% 
  filter(PIN15 != "536602759906000")
```

Made a separate dataset containing 4 records for parcels "734802796634000" and "536602759906000."

```{r}
C.fakedups <- Carteret.sf %>% 
  filter(PIN15 == "734802796634000" | PIN15 == "536602759906000") %>% 
  mutate(Duped_Value = "1")
```

# Processing Master Shapefile

Creating Carteret Master Shapefile containing all uniquely identified parcel info, and the fake duplicate parcel info to retain all parcels in Carteret.

```{r}
CarteretMaster <- rbind(CarteretMaster.0, C.fakedups)
```

Selecting useful variables:

```{r}
CarteretMaster <- CarteretMaster %>%
  select(PIN15, 
         LAND_VALUE, STRUC_VAL, OTHER_VAL,
         OWNER, MAIL_ST, MAIL_CITY, MAIL_STATE, MAIL_ZI5,
         Duped_Value, geometry)

CarteretMaster <- CarteretMaster %>% 
  rename(PIN = PIN15,
         Land_Val = LAND_VALUE, Struc_Val = STRUC_VAL, Other_Val = OTHER_VAL,
         Owner1 = OWNER, Mail_St = MAIL_ST, Mail_City = MAIL_CITY, Mail_State = MAIL_STATE,
         Mail_ZIP = MAIL_ZI5)

CarteretMaster <- CarteretMaster %>%
  st_as_sf() %>% 
  mutate(PIN = as.character(PIN), 
         Acres = st_area(.),
         Acres = set_units(x = Acres, value = "acres"),
         Land_Val = as.numeric(Land_Val),
         Struc_Val = as.numeric(Struc_Val),
         Other_Val = as.numeric(Other_Val), 
         Total_Val = Land_Val+Struc_Val+Other_Val,
         Owner2 = NA_character_,
         Mail_ZIP = as.character(Mail_ZIP),
         Parcel_County = "Carteret",
         ID = row_number(),
         ID = paste0("C", sprintf("%05d", ID)))
```

## Final Check for Master Shapefile

The final inspection suggests there is still one duplicated geometry in the Master Shapefile. Take a manual step to remove the record.

```{r}
CarteretMaster.remove <- CarteretMaster %>% 
  as_tibble() %>% 
  group_by(geometry) %>% 
  tally() %>% 
  filter(n > 1) %>% 
  select(-n) %>% 
  left_join(CarteretMaster)

#The two records are identical. Used distinct() to select one.
CarteretMaster <- CarteretMaster %>% 
  distinct(geometry, .keep_all = TRUE)
```
Writing the final shapefile:

```{r}
if (file.exists("CarteretMaster.shp")) {
  file.remove("CarteretMaster.shp")
}
st_write(CarteretMaster, "CarteretMaster.shp", delete.dsn = TRUE)
```